{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Project\\\\end_to_end_project\\\\Flight_Fare_prediction\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Project\\\\end_to_end_project\\\\Flight_Fare_prediction'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    preprocessor_obj_file_path: Path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mlProject.constants import *\n",
    "from src.mlProject.utils.common import read_yaml, create_directories, save_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            preprocessor_obj_file_path=config.preprocessor_obj_file_path\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from src.mlProject import logger\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_data_transformation(self):\n",
    "\n",
    "        try:\n",
    "            numerical_columns = [\"Total_Stops\",\"Journey_day\",\"Journey_month\",\"Journey_weekday\",\"Journey_year\",\"Dep_Time_Hr\",\n",
    "                                 \"Dep_Time_Min\",\"Arr_Time_Hr\",\"Arr_Time_Min\",\"Duration_Hour\",\"Duration_Minute\"]\n",
    "            categorical_columns = [\n",
    "                \"Airline\",\n",
    "                \"Source\",\n",
    "                \"Destination\",\n",
    "                \n",
    "            ]\n",
    "\n",
    "            num_pipeline= Pipeline(\n",
    "                steps=[\n",
    "                (\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\",StandardScaler())\n",
    "\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            cat_pipeline=Pipeline(\n",
    "\n",
    "                steps=[\n",
    "                (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"one_hot_encoder\",OneHotEncoder()),\n",
    "                (\"scaler\",StandardScaler(with_mean=False))\n",
    "                ]\n",
    "\n",
    "            )\n",
    "\n",
    "            logger.info(f\"Categorical columns: {categorical_columns}\")\n",
    "            logger.info(f\"Numerical columns: {numerical_columns}\")\n",
    "\n",
    "            preprocessor=ColumnTransformer(\n",
    "                [\n",
    "                (\"num_pipeline\",num_pipeline,numerical_columns),\n",
    "                (\"cat_pipelines\",cat_pipeline,categorical_columns)\n",
    "\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            with open('preprocessor.pkl', 'wb') as file:\n",
    "                pickle.dump(preprocessor, file)\n",
    "\n",
    "            return preprocessor\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e \n",
    "       \n",
    "    def initiate_data_transformation(self):\n",
    "        try:\n",
    "            df = pd.read_csv(\"artifacts/data_cleaning/cleaned_data.csv\")\n",
    "\n",
    "            print(df.shape)\n",
    "\n",
    "            logger.info(\"Obtaining preprocessing object\")\n",
    "\n",
    "            preprocessing_obj = self.get_data_transformation()\n",
    "            target_column_name = \"Price\"\n",
    "\n",
    "            numerical_columns = [\"Total_Stops\", \"Journey_day\", \"Journey_month\", \"Journey_weekday\", \"Journey_year\",\n",
    "                                 \"Dep_Time_Hr\", \"Dep_Time_Min\", \"Arr_Time_Hr\", \"Arr_Time_Min\", \"Duration_Hour\",\n",
    "                                 \"Duration_Minute\"]\n",
    "\n",
    "            categorical_columns = [\n",
    "                \"Airline\",\n",
    "                \"Source\",\n",
    "                \"Destination\",\n",
    "            ]\n",
    "\n",
    "            input_feature_df = df.drop(columns=[target_column_name], axis=1)\n",
    "            target_feature_df = df[target_column_name]\n",
    "\n",
    "            print(input_feature_df.shape)\n",
    "            \n",
    "\n",
    "            logger.info(\n",
    "                \"Applying preprocessing object on training dataframe and testing dataframe.\"\n",
    "            )\n",
    "            input_feature_arr = preprocessing_obj.fit_transform(input_feature_df)\n",
    "\n",
    "            logger.info(\"Saved preprocessing object.\")\n",
    "\n",
    "            input_arr = np.c_[\n",
    "                input_feature_arr, np.array(target_feature_df)\n",
    "            ]\n",
    "\n",
    "            transformed_data_df = pd.DataFrame(input_arr)\n",
    "            \n",
    "            save_object(\n",
    "                file_path=self.config.preprocessor_obj_file_path,\n",
    "                obj=preprocessing_obj\n",
    "            )\n",
    "\n",
    "            # Save the transformed data to CSV\n",
    "            transformed_data_path = os.path.join(self.config.root_dir, \"transformed_data.csv\")\n",
    "            transformed_data_df.to_csv(transformed_data_path, index=False)\n",
    "            logger.info(f\"Transformed data saved at: {transformed_data_path}\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-31 17:59:29,073: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-01-31 17:59:29,081: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-01-31 17:59:29,089: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-01-31 17:59:29,089: INFO: common: created directory at: artifacts]\n",
      "[2024-01-31 17:59:29,097: INFO: common: created directory at: artifacts/data_cleaning]\n",
      "(10462, 15)\n",
      "[2024-01-31 17:59:29,145: INFO: 727000088: Obtaining preprocessing object]\n",
      "[2024-01-31 17:59:29,145: INFO: 727000088: Categorical columns: ['Airline', 'Source', 'Destination']]\n",
      "[2024-01-31 17:59:29,145: INFO: 727000088: Numerical columns: ['Total_Stops', 'Journey_day', 'Journey_month', 'Journey_weekday', 'Journey_year', 'Dep_Time_Hr', 'Dep_Time_Min', 'Arr_Time_Hr', 'Arr_Time_Min', 'Duration_Hour', 'Duration_Minute']]\n",
      "(10462, 14)\n",
      "[2024-01-31 17:59:29,161: INFO: 727000088: Applying preprocessing object on training dataframe and testing dataframe.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-31 17:59:29,305: INFO: 727000088: Saved preprocessing object.]\n",
      "[2024-01-31 17:59:30,628: INFO: 727000088: Transformed data saved at: artifacts/data_cleaning\\transformed_data.csv]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_trans_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_trans_config)\n",
    "    data_transformation.initiate_data_transformation()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fprice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
